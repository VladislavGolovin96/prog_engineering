# Финальный отчёт по проекту «AI Multitask»

## Обзор
В проекте реализованы 5 задач с применением готовых ИИ-библиотек (без дообучения моделей):

1) **NLP (Hugging Face + PyTorch):** анализ тональности текста  
2) **Аудио (TensorFlow Hub):** классификация звуков (YAMNet / AudioSet)  
3) **Изображения (PyTorch / torchvision):** классификация (ResNet-50 / ImageNet)  
4) **Видео (Hugging Face + PyTorch):** детекция объектов по кадрам (DETR)  


Среда: macOS (Apple Silicon), Python 3.12, виртуальное окружение `venv`.  
Установка зависимостей — через `requirements.txt` + `constraints.txt` (зафиксированные версии для совместимости).

---

## 1) NLP - анализ тональности текста(Hugging Face + PyTorch)

### Выбранные инструменты и их преимущества
- **Hugging Face Transformers:** единый интерфейс `pipeline`, большое количество предобученных моделей, быстрая интеграция.  
- **PyTorch (MPS на Mac):** стабильная работа на Apple Silicon, высокие показатели производительности

### Модель, принцип работы и причины выбора
- **Модель:** `cardiffnlp/twitter-xlm-roberta-base-sentiment` (многоязычная RoBERTa для работы с текстом).  
- **Принцип:** трансформер получает токенизированный текст ,затем контекстная матрица и линейный классификатор сегрегирует текст на`[negative, neutral, positive]`.  
- **Почему эта модель:** надёжная, широко используемая, поддерживает русский и английский, доступна в HF Hub.

### Датасет (структура и происхождение)
- Модель обучена на наборах твитов/сообщений (разные источники, составленные авторами модели).  
- **Структура типичного датасета сентимента:** `text` + `label` (класс), иногда мета-данные (язык, тема).  
- Модель **не обучали**,а использовали как готовый inference.

### Метрики оценки
- **ML-метрики:** Accuracy, Macro-F1 (важна при дисбалансе классов), Confusion Matrix.  
- **Продуктовые:** Доля «корректно понятых» кейсов по ручной проверке (sample review), время ответа, стабильность тональности на похожих примерах.  
- **Инфраструктурные:** Загрузка CPU/GPU, задержка на 1 запрос, использование MPS (при наличии).

### Особенности реализации и эффективность
- Прямой `pipeline("sentiment-analysis", framework="pt")` + отключённый fast-токенайзер для совместимости.  
- На M-серии Apple задержка на коротком тексте ~50–150 мс после прогрева; память ~0.7–1.2 ГБ.  
- **Вывод:** подходит для CLI/скрипта и пакетной обработки

---

## 2) Аудио — классификация звуков (TensorFlow Hub: YAMNet)

### Инструменты и преимущества
- **TensorFlow Hub:** предобученные модели, простая загрузка, совместимость с `tensorflow-macos`/`metal`.  
- **YAMNet:** компактная CNN, обучена на **AudioSet**

### Модель, принцип и выбор
- **Модель:** `google/yamnet/1` (TF Hub).  
- **Принцип:** WAV → ресемплинг 16 kHz → лог-мел-спектрограмма → CNN (MobileNet-v1) → вероятности по классам AudioSet.  
- **Почему YAMNet:** лёгкая, хорошо документирована, даёт «общую» категоризацию звуков (речь, музыка, аплодисменты и т.п.).

### Датасет
- **AudioSet:** многоклассовые аннотации, фрагменты видео/аудио с короткими звуковыми событиями, иерархия меток.  
- **Структура:** для каждого аудио — набор меток (мульти-лейбл); метки — элементы иерархии AudioSet.

### Метрики оценки
- **ML-метрики:** mAP / AUC (мульти-лейбл), Precision@K, Recall@K.  
- **Продуктовые:** корректность топ-5 для целевых классов (ручная проверка), стабильность на длинных записях.  
- **Инфраструктурные:** задержка на 10-сек фрагменте, потребление памяти, ускорение через Metal Plugin.

### Реализация и эффективность
- CLI: `--audio`, `--topk`, `--json`, `--save-csv`.  
- CPU/MPS на Mac: инференс реального времени для типичных отрывков; RAM ~0.7–1.5 ГБ.  
- **Вывод:** удобная универсальная классификация звука «из коробки». Для точных доменных задач — нужен спец-датасет.

---

## 3) Изображения — классификация (PyTorch / torchvision: ResNet-50)

### Инструменты и преимущества
- **torchvision.models:** устойчивые предобученные веса, встроенные трансформации и категории ImageNet.  
- **PyTorch (MPS):** простая интеграция, ускорение на Apple GPU.

### Модель, принцип и выбор
- **Модель:** `ResNet-50` с весами `ResNet50_Weights.DEFAULT`.  
- **Принцип:** свёрточная сеть с остаточными блоками; вход 224×224; Softmax по классам ImageNet-1k.  
- **Почему ResNet-50:** «золотой стандарт» для базовой классификации, качественные и быстрые веса.

### Датасет
- **ImageNet-1k:** 1000 классов, по ~1000 изображений на класс, общий формат — изображение + метка класса.  
- Веса содержат `meta.categories` — имена классов.

### Метрики оценки
- **ML-метрики:** Top-1 / Top-5 Accuracy (стандарт для ImageNet).  
- **Продуктовые:** доля корректно распознанных целевых классов на реальных данных пользователя.  
- **Инфраструктурные:** задержка на 1 изображение, Throughput при пакетной обработке, использование GPU (MPS).

### Реализация и эффективность
- CLI: `--image`, `--topk`, `--json`, `--save-vis` (наложение Top-1).  
- Трансформации `weights.transforms()`: resize→center crop→normalize — всё «штатно».  
- **Производительность:** мгновенно на CPU/MPS для одиночных изображений; RAM ~0.3–0.8 ГБ.

---

## 4) Видео — детекция объектов (Hugging Face DETR + PyTorch)

### Инструменты и преимущества
- **Transformers pipeline("object-detection"):** быстрый старт без низкоуровневой обвязки.  
- **DETR (facebook/detr-resnet-50):** элегантная архитектура на трансформерах, прямой вывод боксов (без NMS).

### Модель, принцип и выбор
- **Модель:** `facebook/detr-resnet-50` (COCO).  
- **Принцип:** CNN-бэкбон (ResNet) → трансформер-энкодер/декодер → предсказание набора боксов + классов (без анкор-боксов).  
- **Почему DETR:** простота использования, приличное качество на COCO, удобная интеграция с HF `pipeline`.

### Датасет
- **COCO (2017):** 80 классов объектов; формат — изображения/аннотации (bbox, категории).  
- Для видео мы извлекаем **кадры** (каждый N-й) и применяем детектор по кадрам.

### Метрики оценки
- **ML-метрики:** mAP@[.5:.95], mAP@.5 (COCO-стандарт), Precision/Recall для выбранных классов.  
- **Прикладные:** доля кадров, где обнаружены ключевые объекты (например, `person`, `car`), среднее число ложных детекций на минуту.  
- **Инфраструктурные:** FPS (кадров/сек), средняя задержка на кадр, использование GPU (MPS), объём памяти.

### Реализация и эффективность
- CLI: `--video`, `--stride` (шаг по кадрам), `--conf-thres`, `--save-csv`, `--save-preview`.  
- Для ускорения на Mac включён MPS; `stride`=5–15 даёт хороший компромисс между скоростью и полнотой.  
- **Производительность:** на 720p видео при `stride=5` — несколько кадров/сек (зависит от сцены и числа объектов).

---

## 5) Локальная LLM (LM Studio)

### Инструменты и преимущества
- **LM Studio:** локальный запуск LLM (GGUF/MLC-совместимые модели) без сторонних серверов, удобный UI, быстрый старт, кэширование, работа офлайн.  
- **Преимущества локально:** приватность данных, отсутствие сетевых задержек, контроль окружения.

### Модель, принцип и выбор
- **Модели (варианты):** Qwen, Llama-семейство, Mistral-инструкционные.  
- **Принцип:** авто-регрессионная генерация токенов; вывод текста по токену за шаг, с буферизацией в UI.  
- **Почему такой стек:** легко установить, не требует Docker/сложной сборки, стабильная работа на Apple Silicon.

### Датасет
- Используются готовые веса (инструкционно дообученные авторами).  
- При желании можно добавить «локальный контекст» (RAG) через документы пользователя — **в проекте не требуется**.

### Метрики оценки
- **Качество:** субъективная оценка релевантности ответов, «hallucination rate» (процент выдумок), следование инструкции.  
- **Продуктовые:** удовлетворённость пользователя, время до первого токена (TTFT), скорость токенизации/генерации.  
- **Инфраструктурные:** RAM/VRAM, загрузка CPU/GPU, стабильность при длительных сессиях.

### Реализация и эффективность
- Запуск через LM Studio с локальными весами; без дообучения.  
- Для задач, где важны факты, рекомендуется «внешняя валидация» (проверка ссылками/источниками).

---

## Сравнительная таблица по задачам

| Задача | Библиотека/Модель | Датасет (обучение модели) | Выход | Ключевые метрики |
|---|---|---|---|---|
| NLP (тональность) | HF Transformers + PyTorch, `cardiffnlp/...sentiment` | Тексты соцсетей (multi-lang) | label ∈ {neg, neu, pos} + score | Accuracy / Macro-F1 |
| Аудио (YAMNet) | TF Hub `google/yamnet/1` | AudioSet (521 класс) | Top-K классов + score | mAP / Precision@K / Recall@K |
| Изображения (ResNet-50) | torchvision `resnet50` | ImageNet-1k | Top-K классов + score | Top-1 / Top-5 Accuracy |
| Видео (DETR) | HF pipeline DETR | COCO (80 классов) | BBox + label + score | mAP@[.5:.95], FPS |
| Локальная LLM | LM Studio + локальные веса | предобученные (инструкционные) | Текстовая генерация | TTFT, токены/с, субъективная оценка |

---

## Риски и ограничения
- **Обобщение доменов:** предобученные модели (особенно ResNet‑50 / YAMNet / DETR) дают «универсальные» ответы; для узких доменов точность может падать.  
- **Языковые нюансы:** сентимент на смешанных языках/сленге иногда ошибается.  
- **Производительность:** на длинных видео детекция кадр‑за‑кадром затратна — нужен `stride` и/или сэмплинг по времени.

---


